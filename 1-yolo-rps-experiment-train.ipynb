{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ba342a",
   "metadata": {},
   "source": [
    "## Yolo Rock Paper Scissors Notebook\n",
    "\n",
    "This notebook implements the training process for a finetuned YOLO model using a custom Rock-Paper-Scissors dataset.  \n",
    "It covers training, evaluation, and live recognition via your notebook camera.\n",
    "\n",
    "The goal is to build up basic understanding of model training (finetuning) and inference based on a commonly known integration example (rock paper scissors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6589ba",
   "metadata": {},
   "source": [
    "### Dependencies and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1ed0c",
   "metadata": {},
   "source": [
    "We start by installing and importing the necessary libraries. This includes:\n",
    "- `ultralytics` for working with YOLOv8,\n",
    "- `supervision` and `opencv-python` for image processing and visualization,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b16a1bd-d10f-4a3c-bd7c-10a04808039d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install \"ultralytics==8.3.101\" \"supervision==0.25.1\" \"roboflow==1.1.54\" \"opencv-python==4.11.0.86\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0043c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import Image as IPyImage, display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9c1c27",
   "metadata": {},
   "source": [
    "### Training new YOLO Model with Rock Paper Scissors Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff0993",
   "metadata": {},
   "source": [
    "After training, we visualize key metrics such as:\n",
    "- the confusion matrix (which shows how well the model differentiates between classes),\n",
    "- training loss and accuracy plots,\n",
    "- and prediction examples on validation data.\n",
    "\n",
    "This allows us to evaluate the model’s performance qualitatively and quantitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf7b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the Yolov11 Original Pretrained Model\n",
    "#model = YOLO(yolov11_orig_file_path)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Number of epochs to Train\n",
    "epochs = 1\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=\"https://universe.roboflow.com/ds/HNl4FDwSzM?key=Pa24Xd2c7z\",\n",
    "    epochs=epochs,\n",
    "    imgsz=640,\n",
    "    plots=True,\n",
    "    exist_ok=True,\n",
    "    device='mps'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b90be9f",
   "metadata": {},
   "source": [
    "### Check Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e3331",
   "metadata": {},
   "source": [
    "After training, we visualize key metrics such as:\n",
    "\n",
    "- prediction examples on validation data.\n",
    "\n",
    "This allows us to evaluate the model’s performance qualitatively and quantitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results\n",
    "display(IPyImage(filename=f'runs/detect/train/val_batch0_pred.jpg', width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96199ae",
   "metadata": {},
   "source": [
    "### Validate new Trained RPS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runs/detect/train/weights/best.pt\")  # load a trained model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map  # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps  # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db2a783",
   "metadata": {},
   "source": [
    "### Test model with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131608ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Match folders using glob pattern\n",
    "folders = glob.glob('runs/detect/predict*')\n",
    "\n",
    "for folder in folders:\n",
    "    if os.path.isdir(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        print(f\"Deleted: {folder}\")\n",
    "\n",
    "# Load best trained model\n",
    "try:\n",
    "    model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "except NameError:\n",
    "    raise Exception(\"Model not loaded. Make sure `model` is initialized before running this.\")\n",
    "\n",
    "# Run YOLO prediction on some images\n",
    "result_fist = model.predict(source=\"testimages/fist.png\", conf=0.1, save=True, verbose=True)\n",
    "result_paper = model.predict(source=\"testimages/paper.png\", conf=0.1, save=True, verbose=True)\n",
    "result_scissors = model.predict(source=\"testimages/scissors.png\", conf=0.1, save=True, verbose=True)\n",
    "result_all = model.predict(source=\"testimages/all.png\", conf=0.1, save=True, verbose=True)\n",
    "\n",
    "# Display prediction results\n",
    "predicted_images = glob.glob(f'runs/detect/predict*/*.jpg')\n",
    "\n",
    "for img in predicted_images:\n",
    "    display(IPyImage(filename=img, width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf2cee6",
   "metadata": {},
   "source": [
    "### Test model with camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985bafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import display, Image as IPyImage\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Check if model is loaded\n",
    "try:\n",
    "    model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "except NameError:\n",
    "    raise Exception(\"Model not loaded. Make sure `model` is initialized before running this.\")\n",
    "\n",
    "# OpenCV: Open webcam (0 is usually the default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set resolution to 640x480\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "else:\n",
    "    print(\"Starting webcam object detection. Press 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        # Read frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        # Convert OpenCV's BGR to RGB for YOLO + PIL\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.NORMAL_CLONE)\n",
    "\n",
    "        # Run YOLO prediction on the frame\n",
    "        results = model.predict(source=frame_rgb, conf=0.1, save=False, verbose=False)\n",
    "\n",
    "        # Draw results on frame\n",
    "        annotated_frame = results[0].plot()  # YOLOv8 returns list of results; draw annotations\n",
    "\n",
    "        # Display annotated frame in real-time using OpenCV\n",
    "        cv2.imshow('YOLO Live Detection', annotated_frame)\n",
    "\n",
    "        # Press 'q' to break the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Quitting live detection.\")\n",
    "            break\n",
    "\n",
    "    # Release the camera and close window\n",
    "    cap.release()\n",
    "    cv2.destroyWindow('YOLO Live Detection')\n",
    "    cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
